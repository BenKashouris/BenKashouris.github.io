---
layout: default
title: "Online Safety Bill"
date: 2025-07-28
author: "Ben Kashouris"
image: /assets/images/browser_padlock.png
center_content: true
description: A letter I sent to my MP outlining my issues with the Online Safety Bill
---

## Prelude
This is a letter I sent to my MP expressing my concerns about the Online Safety Bill. Feel free to use or adapt it if you'd like to raise similar issues with your own MP.

## Letter
I am writing with some concerns about the current implementation of online safety bill that recently came into effect.

The bill gives Ofcom the power to enforce an encryption back door in encrypted messaging apps such as WhatsApp.  It is mathematically impossible to produce a “secure” back door in encryptions schemes; any such proposal would result in an end to the security of these messaging apps, allowing access to private messages not just to the UK government, but also to foreign governments and to non-state actors. Giving a non-elected government agency the power to require this, is an attack upon public privacy and security. 

Furthermore, the current bill blocks all mature content - not just that of a pornographic nature but also mental health support and LGBTIQA+ content, which is often incredibly important for the very people the bill is attempting to block from seeing this content. It does not just block children from seeing this, but also anyone who does not verify their age. We do not know what we are not being shown, which fundamentally removes these contents from public conversation. Even if you make the argument that people should just verify themselves, this still reduces public conversation because not everyone is going to verify themselves, and because of this there will not be as many eyes on important issues, so the algorithms will not amplify this content. This will result in a massive increase in algorithmic bias, which is already a key issue facing our democracy. 

These factors become an even larger concern when you realise that the bill also blocks violent content, crucially including violent news. Footage such as the murder of George Floyd may not have had the same reach because of this bill. Furthermore, this bill gives increasing power to the government/ big tech to block or inhibit certain political viewpoints, for instance Palestine Action, whatever you think about the proscription of the group. I think it is important that a public conversation was held about the proscription. Under this bill, the discussion would at least be inhibited, and possibly even outrightly banned. This also stops those under 18s from engaging in these discussions, despite the fact that over 16s are to be allowed to vote. These two points are entirely contradictory. 

Moreover, I question the ability of the government to expand this already restrictive bill.

In its current state, the bill is ineffective in blocking under 18s from viewing content like this. The verification is shockingly easy and free to get around, not at all beyond the capabilities of even a moderately “techy” child. It also pushes both children and adults to more “extreme” sites, which will send more money and attention to illegal content. Also, a Children’s Commissioner survey suggests that when children have seen explicit content, 33% of it comes from Instagram and 32% from Snapchat. I would expect that these are unlikely to be on their feed and more likely found through messages. This bill fails to address this. I fundamentally think that this bill has completely missed the point and is a failed attempt at very much needed big-tech regulation.
My final point revolves around the current implementation of the bill. The absolute bare minimum that should have happened before this bill came into effect was an anonymous, government-controlled, open-source verification system that exclusively verifies age and provides no more information than this. There are 3 main issues: <br>
1) The obvious privacy issue with having to verify yourself, with not just porn but also with social media accounts, as this bill blocks, for instance, wine forums. <br>
2) The issue with data leaks- literally the very day the bill came into effect there was a data leak in the verification system of the “Tea” app, which resulted in users having their driving licenses leaked. <br>
3) The issues with scams: by normalising ID verification or banking verification, this bill will increase the number of people falling for scams. It is not hard to set up a website and add a fake verification system that harvests people’s information or just takes money out of their bank accounts. Furthermore, the verification being made the responsibility of companies puts smaller organisations or non-profit organisations at a massive disadvantage. Wikipedia, for instance, is considering withdrawing from the UK, a major loss that would put our country at a massive disadvantage. It also means that big tech will have even more of a monopoly over online discourse, as they will be the only ones who can afford to run these verification systems. Whilst the bill attempts to deal with this, it fails.

I believe there were reasonable alternatives to this. First and foremost, I think that government requirement and enforcement of child modes on both an operating system and app layer are important. This will, of course, require some level of education for parents. I would then expand the definition of child neglect to include neglecting to protect their children online - with the right tools from tech companies it should not be beyond the scope of parents. In the long term, I think the political momentum should be looking towards enforcing content-algorithms to be open-source, allowing public scrutiny over them. I think that with time, this would be one of the biggest gains in public health in recent years.

In its current state, this bill increases the power given to big tech; is ineffective at the very things it attempts; raises concerns about security and the free press and is a significant increase in surveillance and a massive decrease in privacy.

